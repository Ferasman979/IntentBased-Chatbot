{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1582026,"sourceType":"datasetVersion","datasetId":935560}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-30T22:05:36.180408Z","iopub.execute_input":"2023-12-30T22:05:36.180916Z","iopub.status.idle":"2023-12-30T22:05:36.189719Z","shell.execute_reply.started":"2023-12-30T22:05:36.180878Z","shell.execute_reply":"2023-12-30T22:05:36.188671Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"/kaggle/input/chatbots-intent-recognition-dataset/Intent.json\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importing Libraries and the dataset**\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport json\nimport re\nimport tensorflow as tf\nimport random\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nwith open('/kaggle/input/chatbots-intent-recognition-dataset/Intent.json') as f:\n    intents = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:36.191752Z","iopub.execute_input":"2023-12-30T22:05:36.192600Z","iopub.status.idle":"2023-12-30T22:05:37.446762Z","shell.execute_reply.started":"2023-12-30T22:05:36.192557Z","shell.execute_reply":"2023-12-30T22:05:37.445824Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Preprocessing and cleaning data","metadata":{}},{"cell_type":"code","source":"# Text cleaning function\ndef clean(line):\n    # Replace any character that is not a letter, period, question mark, exclamation mark, or single quote with a space\n    line = re.sub(r'[^a-zA-z.?!\\']', ' ', line)\n    # Replace consecutive spaces with a single space\n    line = re.sub(r'[ ]+', ' ', line)\n    return line","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.447999Z","iopub.execute_input":"2023-12-30T22:05:37.449013Z","iopub.status.idle":"2023-12-30T22:05:37.455272Z","shell.execute_reply.started":"2023-12-30T22:05:37.448974Z","shell.execute_reply":"2023-12-30T22:05:37.453706Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Initialize empty lists to store preprocessed input data and corresponding target labels\ninput_list, target_list = [], []\n\n# Initialize an empty dictionary to store responses associated with each intent\nintent_document = {}\n\n# Loop over each intent data in the 'intents' array of the 'intents' dictionary\nfor intent_data in intents['intents']:\n    \n    # Check if the intent label is not already a key in the intent_document dictionary\n    if intent_data['intent'] not in intent_document:\n        # If not, initialize an empty list for that intent label in the intent_document dictionary\n        intent_document[intent_data['intent']] = []\n        \n    # Loop over each text data associated with the current intent\n    for text_data in intent_data['text']:\n        # Clean and preprocess the text data using the 'clean' function and append to input_list\n        input_list.append(clean(text_data))\n        # Append the intent label to target_list for each text example\n        target_list.append(intent_data['intent'])\n        \n    # Loop over each response data associated with the current intent\n    for response_data in intent_data['responses']:\n        # Append the response data to the list associated with the current intent label in intent_document\n        intent_document[intent_data['intent']].append(response_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.458613Z","iopub.execute_input":"2023-12-30T22:05:37.459006Z","iopub.status.idle":"2023-12-30T22:05:37.469881Z","shell.execute_reply.started":"2023-12-30T22:05:37.458973Z","shell.execute_reply":"2023-12-30T22:05:37.468483Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Tokenization function for input data\ndef tokenize_data(input_list):\n    # Create a Tokenizer object with filters set to an empty string and out-of-vocabulary token as '<unk>'\n    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n    \n    # Fit the tokenizer on the input text data to build the vocabulary\n    tokenizer.fit_on_texts(input_list)\n    \n    # Convert the input text data to sequences of tokens using the trained tokenizer\n    input_seq = tokenizer.texts_to_sequences(input_list)\n\n    # Pad the sequences to ensure uniform length (padding added to the beginning)\n    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, padding='pre')\n    \n    # Return the trained tokenizer and the padded input sequences\n    return tokenizer, input_seq\n\n# Preprocess input data\n# Apply the tokenize_data function to the 'input_list' to obtain a trained tokenizer and padded input sequences\ntokenizer, input_tensor = tokenize_data(input_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.471561Z","iopub.execute_input":"2023-12-30T22:05:37.472057Z","iopub.status.idle":"2023-12-30T22:05:37.489947Z","shell.execute_reply.started":"2023-12-30T22:05:37.472022Z","shell.execute_reply":"2023-12-30T22:05:37.488412Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Function to create categorical targets and provide index-to-label mapping\ndef create_categorical_target(targets):\n    # Dictionary to store a mapping from unique target labels to integer indices\n    word = {}\n    # List to store integer indices corresponding to each target label\n    categorical_target = []\n    # Counter to assign unique indices to unique target labels\n    counter = 0\n    \n    # Loop over target labels\n    for trg in targets:\n        # Check if the current target label is not already in the dictionary\n        if trg not in word:\n            # Assign a unique integer index to the current target label\n            word[trg] = counter\n            # Increment the counter for the next unique target label\n            counter += 1\n        # Append the integer index corresponding to the current target label to the list\n        categorical_target.append(word[trg])\n       \n    # Convert the list of integer indices to a one-hot encoded tensor\n    categorical_tensor = tf.keras.utils.to_categorical(categorical_target, num_classes=len(word), dtype='int32')\n    \n    # Return the one-hot encoded tensor and a dictionary mapping integer indices to target labels\n    return categorical_tensor, dict((v, k) for k, v in word.items())\n\n# Preprocess output data\n# Apply the create_categorical_target function to the 'targets' list\ntarget_tensor, trg_index_word = create_categorical_target(target_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.491496Z","iopub.execute_input":"2023-12-30T22:05:37.491921Z","iopub.status.idle":"2023-12-30T22:05:37.505092Z","shell.execute_reply.started":"2023-12-30T22:05:37.491889Z","shell.execute_reply":"2023-12-30T22:05:37.503769Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"print('input shape: {} and output shape: {}'.format(input_tensor.shape, target_tensor.shape))","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.509447Z","iopub.execute_input":"2023-12-30T22:05:37.509857Z","iopub.status.idle":"2023-12-30T22:05:37.520534Z","shell.execute_reply.started":"2023-12-30T22:05:37.509825Z","shell.execute_reply":"2023-12-30T22:05:37.519390Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"input shape: (143, 9) and output shape: (143, 22)\n","output_type":"stream"}]},{"cell_type":"code","source":"# hyperparameters\nepochs=50\nvocab_size=len(tokenizer.word_index) + 1\nembed_dim=512\nunits=128\ntarget_length=target_tensor.shape[1]","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.522227Z","iopub.execute_input":"2023-12-30T22:05:37.522633Z","iopub.status.idle":"2023-12-30T22:05:37.532349Z","shell.execute_reply.started":"2023-12-30T22:05:37.522600Z","shell.execute_reply":"2023-12-30T22:05:37.531003Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# build RNN Model with tensorflow\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embed_dim),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, dropout=0.2)),\n    tf.keras.layers.Dense(units, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(target_length, activation='softmax')\n])\n\noptimizer = tf.keras.optimizers.Adam(lr=1e-2)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:37.534012Z","iopub.execute_input":"2023-12-30T22:05:37.534413Z","iopub.status.idle":"2023-12-30T22:05:38.243203Z","shell.execute_reply.started":"2023-12-30T22:05:37.534368Z","shell.execute_reply":"2023-12-30T22:05:38.242047Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_1 (Embedding)     (None, None, 512)         66048     \n                                                                 \n bidirectional_1 (Bidirecti  (None, 256)               656384    \n onal)                                                           \n                                                                 \n dense_2 (Dense)             (None, 128)               32896     \n                                                                 \n dropout_1 (Dropout)         (None, 128)               0         \n                                                                 \n dense_3 (Dense)             (None, 22)                2838      \n                                                                 \n=================================================================\nTotal params: 758166 (2.89 MB)\nTrainable params: 758166 (2.89 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n\n# train the model\nmodel.fit(input_tensor, target_tensor, epochs=epochs, callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:38.246476Z","iopub.execute_input":"2023-12-30T22:05:38.248095Z","iopub.status.idle":"2023-12-30T22:05:51.516680Z","shell.execute_reply.started":"2023-12-30T22:05:38.248017Z","shell.execute_reply":"2023-12-30T22:05:51.515669Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Epoch 1/50\n5/5 [==============================] - 5s 44ms/step - loss: 3.0838 - accuracy: 0.1189\nEpoch 2/50\n5/5 [==============================] - 0s 43ms/step - loss: 3.0501 - accuracy: 0.1259\nEpoch 3/50\n5/5 [==============================] - 0s 42ms/step - loss: 3.0088 - accuracy: 0.2238\nEpoch 4/50\n5/5 [==============================] - 0s 44ms/step - loss: 2.9529 - accuracy: 0.2308\nEpoch 5/50\n5/5 [==============================] - 0s 44ms/step - loss: 2.8552 - accuracy: 0.3497\nEpoch 6/50\n5/5 [==============================] - 0s 42ms/step - loss: 2.7261 - accuracy: 0.3217\nEpoch 7/50\n5/5 [==============================] - 0s 42ms/step - loss: 2.5477 - accuracy: 0.3986\nEpoch 8/50\n5/5 [==============================] - 0s 42ms/step - loss: 2.2824 - accuracy: 0.3916\nEpoch 9/50\n5/5 [==============================] - 0s 43ms/step - loss: 2.0492 - accuracy: 0.3846\nEpoch 10/50\n5/5 [==============================] - 0s 43ms/step - loss: 1.8437 - accuracy: 0.4615\nEpoch 11/50\n5/5 [==============================] - 0s 43ms/step - loss: 1.5079 - accuracy: 0.5524\nEpoch 12/50\n5/5 [==============================] - 0s 43ms/step - loss: 1.2739 - accuracy: 0.6294\nEpoch 13/50\n5/5 [==============================] - 0s 42ms/step - loss: 1.2002 - accuracy: 0.6224\nEpoch 14/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.9987 - accuracy: 0.6853\nEpoch 15/50\n5/5 [==============================] - 0s 40ms/step - loss: 0.8803 - accuracy: 0.7413\nEpoch 16/50\n5/5 [==============================] - 0s 41ms/step - loss: 0.7575 - accuracy: 0.7483\nEpoch 17/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.6127 - accuracy: 0.8252\nEpoch 18/50\n5/5 [==============================] - 0s 40ms/step - loss: 0.4717 - accuracy: 0.8601\nEpoch 19/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.4882 - accuracy: 0.8252\nEpoch 20/50\n5/5 [==============================] - 0s 45ms/step - loss: 0.3181 - accuracy: 0.9231\nEpoch 21/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.3833 - accuracy: 0.9021\nEpoch 22/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.3072 - accuracy: 0.9301\nEpoch 23/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.2858 - accuracy: 0.9091\nEpoch 24/50\n5/5 [==============================] - 0s 44ms/step - loss: 0.2465 - accuracy: 0.9301\nEpoch 25/50\n5/5 [==============================] - 0s 41ms/step - loss: 0.1831 - accuracy: 0.9510\nEpoch 26/50\n5/5 [==============================] - 0s 41ms/step - loss: 0.1605 - accuracy: 0.9580\nEpoch 27/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.1426 - accuracy: 0.9650\nEpoch 28/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.1436 - accuracy: 0.9650\nEpoch 29/50\n5/5 [==============================] - 0s 44ms/step - loss: 0.1376 - accuracy: 0.9720\nEpoch 30/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.0857 - accuracy: 0.9930\nEpoch 31/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.1264 - accuracy: 0.9720\nEpoch 32/50\n5/5 [==============================] - 0s 44ms/step - loss: 0.0704 - accuracy: 0.9720\nEpoch 33/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.0775 - accuracy: 0.9860\nEpoch 34/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.0882 - accuracy: 0.9650\nEpoch 35/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.0394 - accuracy: 1.0000\nEpoch 36/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.0742 - accuracy: 0.9790\nEpoch 37/50\n5/5 [==============================] - 0s 43ms/step - loss: 0.0605 - accuracy: 0.9790\nEpoch 38/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.0644 - accuracy: 0.9930\nEpoch 39/50\n5/5 [==============================] - 0s 42ms/step - loss: 0.0573 - accuracy: 0.9930\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x786d6981f8b0>"},"metadata":{}}]},{"cell_type":"code","source":"def response(sentence):\n    sent_seq = []\n    doc = nlp(repr(sentence))\n    \n    # split the input sentences into words\n    for token in doc:\n        if token.text in tokenizer.word_index:\n            sent_seq.append(tokenizer.word_index[token.text])\n\n        # handle the unknown words error\n        else:\n            sent_seq.append(tokenizer.word_index['<unk>'])\n\n    sent_seq = tf.expand_dims(sent_seq, 0)\n    # predict the category of input sentences\n    pred = model(sent_seq)\n\n    pred_class = np.argmax(pred.numpy(), axis=1)\n    \n    # choice a random response for predicted sentence\n    return random.choice(intent_document[trg_index_word[pred_class[0]]]), trg_index_word[pred_class[0]]\n\n# chat with bot\nprint(\"Note: Enter 'quit' to break the loop.\")\nwhile True:\n    input_ = input('You: ')\n    if input_.lower() == 'quit':\n        break\n    res, typ = response(input_)\n    print('Bot: {} -- TYPE: {}'.format(res, typ))\n    print()","metadata":{"execution":{"iopub.status.busy":"2023-12-30T22:05:51.519542Z","iopub.execute_input":"2023-12-30T22:05:51.520322Z","iopub.status.idle":"2023-12-30T22:44:47.142131Z","shell.execute_reply.started":"2023-12-30T22:05:51.520276Z","shell.execute_reply":"2023-12-30T22:44:47.140876Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Note: Enter 'quit' to break the loop.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  what is time\n"},{"name":"stdout","text":"Bot: One sec -- TYPE: TimeQuery\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  quit\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}